{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_columns = df.select_dtypes(include=['object']).columns\n",
    "df_numerical = df.drop(columns=string_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerFriendCount</th>\n",
       "      <th>reviewerNumReviews</th>\n",
       "      <th>reviewerFirstCount</th>\n",
       "      <th>reviewerUsefulCount</th>\n",
       "      <th>reviewerCoolCount</th>\n",
       "      <th>reviewerFunnyCount</th>\n",
       "      <th>reviewerComplimentCount</th>\n",
       "      <th>reviewerTipCount</th>\n",
       "      <th>reviewerFanCount</th>\n",
       "      <th>resReviewCount</th>\n",
       "      <th>...</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>reviewRating_1</th>\n",
       "      <th>reviewRating_2</th>\n",
       "      <th>reviewRating_3</th>\n",
       "      <th>reviewRating_4</th>\n",
       "      <th>reviewRating_5</th>\n",
       "      <th>reviewRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002337</td>\n",
       "      <td>0.018008</td>\n",
       "      <td>0.018008</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.776256</td>\n",
       "      <td>0.427350</td>\n",
       "      <td>0.139140</td>\n",
       "      <td>0.528655</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.068376</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063927</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.413333</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.017850</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.005078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237443</td>\n",
       "      <td>0.290598</td>\n",
       "      <td>0.120548</td>\n",
       "      <td>0.535201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.070761</td>\n",
       "      <td>0.462835</td>\n",
       "      <td>0.462835</td>\n",
       "      <td>0.075869</td>\n",
       "      <td>0.034472</td>\n",
       "      <td>0.023258</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.010157</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123288</td>\n",
       "      <td>0.170940</td>\n",
       "      <td>0.167460</td>\n",
       "      <td>0.564683</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewerFriendCount  reviewerNumReviews  reviewerFirstCount  \\\n",
       "0             0.002337            0.018008            0.018008   \n",
       "1             0.000000            0.001149            0.001149   \n",
       "2             0.000425            0.003831            0.003831   \n",
       "3             0.017850            0.022605            0.022605   \n",
       "4             0.070761            0.462835            0.462835   \n",
       "\n",
       "   reviewerUsefulCount  reviewerCoolCount  reviewerFunnyCount  \\\n",
       "0             0.001885           0.000254            0.000279   \n",
       "1             0.000000           0.000000            0.000000   \n",
       "2             0.000276           0.000000            0.000056   \n",
       "3             0.001609           0.000406            0.000335   \n",
       "4             0.075869           0.034472            0.023258   \n",
       "\n",
       "   reviewerComplimentCount  reviewerTipCount  reviewerFanCount  \\\n",
       "0                 0.000050          0.000000          0.001563   \n",
       "1                 0.000000          0.000000          0.000000   \n",
       "2                 0.000000          0.000000          0.000000   \n",
       "3                 0.000150          0.005078          0.000000   \n",
       "4                 0.007082          0.010157          0.109375   \n",
       "\n",
       "   resReviewCount  ...  verb_count  adj_count  polarity  subjectivity  \\\n",
       "0             841  ...    0.776256   0.427350  0.139140      0.528655   \n",
       "1             841  ...    0.068493   0.068376  0.466667      0.566667   \n",
       "2             841  ...    0.063927   0.042735  0.413333      0.720000   \n",
       "3             841  ...    0.237443   0.290598  0.120548      0.535201   \n",
       "4             841  ...    0.123288   0.170940  0.167460      0.564683   \n",
       "\n",
       "   reviewRating_1  reviewRating_2  reviewRating_3  reviewRating_4  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               1               0   \n",
       "3               0               0               1               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   reviewRating_5  reviewRating  \n",
       "0               1             5  \n",
       "1               1             5  \n",
       "2               0             3  \n",
       "3               0             3  \n",
       "4               1             5  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_continuous = df_numerical.drop([\"flagged\"] ,axis=1 )\n",
    "y = df_numerical['flagged']\n",
    "X_continuous.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fongj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fongj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fongj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fongj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fongj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fongj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fongj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fongj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fongj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fongj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fongj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fongj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fongj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fongj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "# Assuming X_continuous is your continuous features and y is your target variable\n",
    "model = LogisticRegression()  # You can choose a different model\n",
    "rfe = RFE(model, n_features_to_select=20)  # Adjust the number of features as needed\n",
    "X_continuous_selected = rfe.fit_transform(X_continuous, y)\n",
    "selected_continuous_features = X_continuous.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reviewerFriendCount', 'reviewerNumReviews', 'reviewerFirstCount',\n",
       "       'reviewerUsefulCount', 'reviewerCoolCount', 'reviewerFunnyCount',\n",
       "       'reviewerComplimentCount', 'reviewerTipCount', 'reviewerFanCount',\n",
       "       'EMAIL_ADDRESS_count', 'NRP_count', 'PERSON_count',\n",
       "       'date_diff_joinedandreviewed', 'Num_Char', 'Num_Punc', 'verb_count',\n",
       "       'adj_count', 'polarity', 'reviewRating_1', 'reviewRating_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_continuous_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features_selected = X_continuous[selected_continuous_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features_selected, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      6234\n",
      "           1       0.76      0.70      0.73      1853\n",
      "\n",
      "    accuracy                           0.88      8087\n",
      "   macro avg       0.84      0.82      0.83      8087\n",
      "weighted avg       0.88      0.88      0.88      8087\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['DATE_TIME', 'EMAIL_ADDRESS', 'NRP', 'LOCATION', 'PERSON', 'PHONE_NUMBER', 'clean_tokens', 'preprocessed']\n",
    "X_tokens = df[tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.feature_selection import SelectKBest, chi2\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Assuming X_tokens is your DataFrame with columns containing lists of strings\n",
    "# # Assuming y is your target variable\n",
    "\n",
    "# # Convert lists of strings into a single string for each row\n",
    "# X_tokens['combined_text'] = X_tokens.apply(lambda row: ' '.join(row), axis=1)\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_tokens['combined_text'], y, test_size=0.3, random_state=42)\n",
    "\n",
    "# # TF-IDF vectorization\n",
    "# tfidf_vectorizer = TfidfVectorizer()\n",
    "# X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "# X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# # Feature selection using chi-squared test\n",
    "# k_best = 100  # Adjust as needed\n",
    "# selector = SelectKBest(chi2, k=k_best)\n",
    "# X_train_selected = selector.fit_transform(X_train_tfidf, y_train)\n",
    "# X_test_selected = selector.transform(X_test_tfidf)\n",
    "\n",
    "# # Display selected features\n",
    "# selected_features = tfidf_vectorizer.get_feature_names_out()[selector.get_support()]\n",
    "# print(\"Selected Features:\", selected_features)\n",
    "\n",
    "# # Train a machine learning model (e.g., RandomForest) on the selected features\n",
    "# model = RandomForestClassifier()\n",
    "# model.fit(X_train_selected, y_train)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = model.predict(X_test_selected)\n",
    "\n",
    "# # Evaluate the model\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Model Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = pd.concat([X_continuous[selected_continuous_features], X_tokens, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerFriendCount</th>\n",
       "      <th>reviewerNumReviews</th>\n",
       "      <th>reviewerFirstCount</th>\n",
       "      <th>reviewerUsefulCount</th>\n",
       "      <th>reviewerCoolCount</th>\n",
       "      <th>reviewerFunnyCount</th>\n",
       "      <th>reviewerComplimentCount</th>\n",
       "      <th>reviewerTipCount</th>\n",
       "      <th>reviewerFanCount</th>\n",
       "      <th>EMAIL_ADDRESS_count</th>\n",
       "      <th>...</th>\n",
       "      <th>reviewRating_2</th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>EMAIL_ADDRESS</th>\n",
       "      <th>NRP</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>PERSON</th>\n",
       "      <th>PHONE_NUMBER</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>flagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002337</td>\n",
       "      <td>0.018008</td>\n",
       "      <td>0.018008</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>['the previous night', 'four hours and thirty-...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['English']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Willy Wonka', 'Mickey', 'Minnie Mouse', 'Jac...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['unlike', 'next', 'eaten', 'previous', 'night...</td>\n",
       "      <td>['unlike', 'next', 'wed', 'eaten', 'previous',...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>['an evening', 'a least 4 hours']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Grant Achatz']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['probably', 'one', 'best', 'meals', 'ever', '...</td>\n",
       "      <td>['probably', 'one', 'best', 'meal', 'ive', 'ev...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['service', 'impeccable', 'experience', 'prese...</td>\n",
       "      <td>['service', 'impeccable', 'experience', 'prese...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.017850</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.005078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>['5 seconds']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Jackson Pollock', 'Grant Achatz']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['problem', 'places', 'like', 'given', 'exhorb...</td>\n",
       "      <td>['problem', 'place', 'like', 'given', 'exhorbi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.070761</td>\n",
       "      <td>0.462835</td>\n",
       "      <td>0.462835</td>\n",
       "      <td>0.075869</td>\n",
       "      <td>0.034472</td>\n",
       "      <td>0.023258</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.010157</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>['a few days']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['American']</td>\n",
       "      <td>['Chicago']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['idea', 'write', 'review', 'dining', 'alinea'...</td>\n",
       "      <td>['idea', 'write', 'review', 'dining', 'alinea'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewerFriendCount  reviewerNumReviews  reviewerFirstCount  \\\n",
       "0             0.002337            0.018008            0.018008   \n",
       "1             0.000000            0.001149            0.001149   \n",
       "2             0.000425            0.003831            0.003831   \n",
       "3             0.017850            0.022605            0.022605   \n",
       "4             0.070761            0.462835            0.462835   \n",
       "\n",
       "   reviewerUsefulCount  reviewerCoolCount  reviewerFunnyCount  \\\n",
       "0             0.001885           0.000254            0.000279   \n",
       "1             0.000000           0.000000            0.000000   \n",
       "2             0.000276           0.000000            0.000056   \n",
       "3             0.001609           0.000406            0.000335   \n",
       "4             0.075869           0.034472            0.023258   \n",
       "\n",
       "   reviewerComplimentCount  reviewerTipCount  reviewerFanCount  \\\n",
       "0                 0.000050          0.000000          0.001563   \n",
       "1                 0.000000          0.000000          0.000000   \n",
       "2                 0.000000          0.000000          0.000000   \n",
       "3                 0.000150          0.005078          0.000000   \n",
       "4                 0.007082          0.010157          0.109375   \n",
       "\n",
       "   EMAIL_ADDRESS_count  ...  reviewRating_2  \\\n",
       "0                  0.0  ...               0   \n",
       "1                  0.0  ...               0   \n",
       "2                  0.0  ...               0   \n",
       "3                  0.0  ...               0   \n",
       "4                  0.0  ...               0   \n",
       "\n",
       "                                           DATE_TIME  EMAIL_ADDRESS  \\\n",
       "0  ['the previous night', 'four hours and thirty-...             []   \n",
       "1                  ['an evening', 'a least 4 hours']             []   \n",
       "2                                                 []             []   \n",
       "3                                      ['5 seconds']             []   \n",
       "4                                     ['a few days']             []   \n",
       "\n",
       "            NRP     LOCATION  \\\n",
       "0   ['English']           []   \n",
       "1            []           []   \n",
       "2            []           []   \n",
       "3            []           []   \n",
       "4  ['American']  ['Chicago']   \n",
       "\n",
       "                                              PERSON  PHONE_NUMBER  \\\n",
       "0  ['Willy Wonka', 'Mickey', 'Minnie Mouse', 'Jac...            []   \n",
       "1                                   ['Grant Achatz']            []   \n",
       "2                                                 []            []   \n",
       "3                ['Jackson Pollock', 'Grant Achatz']            []   \n",
       "4                                                 []            []   \n",
       "\n",
       "                                        clean_tokens  \\\n",
       "0  ['unlike', 'next', 'eaten', 'previous', 'night...   \n",
       "1  ['probably', 'one', 'best', 'meals', 'ever', '...   \n",
       "2  ['service', 'impeccable', 'experience', 'prese...   \n",
       "3  ['problem', 'places', 'like', 'given', 'exhorb...   \n",
       "4  ['idea', 'write', 'review', 'dining', 'alinea'...   \n",
       "\n",
       "                                        preprocessed  flagged  \n",
       "0  ['unlike', 'next', 'wed', 'eaten', 'previous',...        0  \n",
       "1  ['probably', 'one', 'best', 'meal', 'ive', 'ev...        0  \n",
       "2  ['service', 'impeccable', 'experience', 'prese...        0  \n",
       "3  ['problem', 'place', 'like', 'given', 'exhorbi...        0  \n",
       "4  ['idea', 'write', 'review', 'dining', 'alinea'...        0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final.to_csv(\"selected_features.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
