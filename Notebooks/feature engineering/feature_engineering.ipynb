{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fongj\\AppData\\Local\\Temp\\ipykernel_12164\\3463287791.py:2: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"Processed_df.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"Processed_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled Review Summaries:\n",
      "0        I won't recount every course, just highlight t...\n",
      "1        Having Grant Achatz prepare our dessert was am...\n",
      "2        Food was not mouth watering, tasted like it it...\n",
      "3        The problem with places like this, given the e...\n",
      "4        I think everyone has a unique experience with ...\n",
      "                               ...                        \n",
      "26951    There must be some kind of contest to see who ...\n",
      "26952    Yellow Rose is a favorite of mine.\\nThe food i...\n",
      "26953    We ate there because the odd wicker seats were...\n",
      "26954    It's a non pretentious bar with video games an...\n",
      "26955    A gorgeous shy young teen asked the owner if s...\n",
      "Name: reviewSummary, Length: 26956, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from summa import summarizer\n",
    "\n",
    "def generate_summary(text):\n",
    "    summary = summarizer.summarize(text, ratio=0.3)  # You can adjust the ratio as needed\n",
    "    # Check if the summary is blank\n",
    "    if not summary:\n",
    "        return text  # Return the original review if the summary is blank\n",
    "    else:\n",
    "        return summary\n",
    "\n",
    "# Apply the generate_summary function to create a new column with summaries\n",
    "df['reviewSummary'] = df['reviewContent'].apply(generate_summary)\n",
    "\n",
    "# Display the first few rows of the dataFrame with the summaries\n",
    "print(\"Sampled Review Summaries:\")\n",
    "print(df['reviewSummary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature engineering: polarity and subjectivity\n",
    "\n",
    "Polarity: numerical score that quantifies the sentiment of the text on a continuous scale. It measures how positive or negative the text is. Polarity scores typically range from -1 (extremely negative) to 1 (extremely positive), with 0 indicating neutral sentiment.\n",
    "\n",
    "Subjectivity: Subjectivity measures the degree to which the text is subjective or opinion-based rather than objective. Subjectivity is also represented as a numerical score ranging from 0 to 1. A score closer to 0 suggests that the text is more objective, factual, or informational. A score closer to 1 suggests that the text is more subjective and opinion-based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "import string\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = WordPunctTokenizer()\n",
    "df['tokens'] = df['reviewContent'].apply(tokenizer.tokenize)\n",
    "\n",
    "# Define a function to remove stopwords and punctuation\n",
    "def preprocess_text(tokens):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word.lower() for word in tokens]  # Convert to lowercase\n",
    "    tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in string.punctuation]  # Remove punctuation\n",
    "    tokens = [word for word in tokens if len(word) > 1]  # Remove single-character words\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing to the 'tokens' column\n",
    "df['clean_tokens'] = df['tokens'].apply(preprocess_text)\n",
    "\n",
    "# Join the clean tokens back into sentences\n",
    "df['clean_text'] = df['clean_tokens'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Sentiment Analysis using TextBlob\n",
    "df['sentiment'] = df['clean_text'].apply(lambda x: TextBlob(x).sentiment)\n",
    "\n",
    "# Extract polarity and subjectivity scores from the sentiment analysis\n",
    "df['polarity'] = df['sentiment'].apply(lambda x: x.polarity)\n",
    "df['subjectivity'] = df['sentiment'].apply(lambda x: x.subjectivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N-gram analysis (common phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-gram: go back - Frequency: 2121\n",
      "N-gram: really good - Frequency: 1303\n",
      "N-gram: first time - Frequency: 1154\n",
      "N-gram: food good - Frequency: 1143\n",
      "N-gram: great food - Frequency: 1094\n",
      "N-gram: deep dish - Frequency: 1061\n",
      "N-gram: pretty good - Frequency: 1013\n",
      "N-gram: food great - Frequency: 980\n",
      "N-gram: great place - Frequency: 941\n",
      "N-gram: love place - Frequency: 916\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "# Define the n-gram range (e.g., 2 for bigrams)\n",
    "ngram_range = 2  # For bigrams (adjust as needed)\n",
    "\n",
    "# Function to extract n-grams from a list of tokens\n",
    "def extract_ngrams(tokens, n):\n",
    "    return list(ngrams(tokens, n))\n",
    "\n",
    "# Extract n-grams and store them in a new column\n",
    "df['ngrams'] = df['clean_tokens'].apply(lambda x: extract_ngrams(x, ngram_range))\n",
    "\n",
    "# Flatten the list of n-grams\n",
    "all_ngrams = [ngram for ngram_list in df['ngrams'] for ngram in ngram_list]\n",
    "\n",
    "# Count the frequency of each n-gram\n",
    "ngram_freq = Counter(all_ngrams)\n",
    "\n",
    "# Print the most common n-grams and their frequencies\n",
    "most_common_ngrams = ngram_freq.most_common(10)\n",
    "for ngram, freq in most_common_ngrams:\n",
    "    print(f\"N-gram: {' '.join(ngram)} - Frequency: {freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find most common phrases of fake vs real reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common n-grams for flagged 'Y' reviews:\n",
      "N-gram: go back - Frequency: 391\n",
      "N-gram: great food - Frequency: 359\n",
      "N-gram: food good - Frequency: 279\n",
      "N-gram: great place - Frequency: 275\n",
      "N-gram: food great - Frequency: 272\n",
      "N-gram: love place - Frequency: 266\n",
      "N-gram: first time - Frequency: 258\n",
      "N-gram: good food - Frequency: 230\n",
      "N-gram: salad bar - Frequency: 224\n",
      "N-gram: great service - Frequency: 217\n",
      "\n",
      "Most common n-grams for flagged 'N' reviews:\n",
      "N-gram: go back - Frequency: 1730\n",
      "N-gram: really good - Frequency: 1134\n",
      "N-gram: deep dish - Frequency: 900\n",
      "N-gram: first time - Frequency: 896\n",
      "N-gram: pretty good - Frequency: 876\n",
      "N-gram: food good - Frequency: 864\n",
      "N-gram: next time - Frequency: 768\n",
      "N-gram: great food - Frequency: 735\n",
      "N-gram: come back - Frequency: 717\n",
      "N-gram: food great - Frequency: 708\n"
     ]
    }
   ],
   "source": [
    "flagged_Y_df = df[df['flagged'] == 1]\n",
    "flagged_N_df = df[df['flagged'] == 0]\n",
    "\n",
    "# Flatten the list of n-grams for each subset\n",
    "ngrams_Y = [ngram for ngram_list in flagged_Y_df['ngrams'] for ngram in ngram_list]\n",
    "ngrams_N = [ngram for ngram_list in flagged_N_df['ngrams'] for ngram in ngram_list]\n",
    "\n",
    "# Count the frequency of each n-gram for each subset\n",
    "ngram_freq_Y = Counter(ngrams_Y)\n",
    "ngram_freq_N = Counter(ngrams_N)\n",
    "\n",
    "# Print the most common n-grams and their frequencies for each category\n",
    "most_common_ngrams_Y = ngram_freq_Y.most_common(10)\n",
    "most_common_ngrams_N = ngram_freq_N.most_common(10)\n",
    "\n",
    "print(\"Most common n-grams for flagged 'Y' reviews:\")\n",
    "for ngram, freq in most_common_ngrams_Y:\n",
    "    print(f\"N-gram: {' '.join(ngram)} - Frequency: {freq}\")\n",
    "\n",
    "print(\"\\nMost common n-grams for flagged 'N' reviews:\")\n",
    "for ngram, freq in most_common_ngrams_N:\n",
    "    print(f\"N-gram: {' '.join(ngram)} - Frequency: {freq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of common n-grams for both 'Y' and 'N' reviews\n",
    "common_ngrams_Y = [(\"go\", \"back\"), (\"great\", \"food\"), (\"food\", \"good\"), (\"great\", \"place\"), (\"food\", \"great\"), (\"love\", \"place\"), (\"first\", \"time\"), (\"good\", \"food\"), (\"salad\", \"bar\"), (\"great\", \"service\")]\n",
    "common_ngrams_N = [(\"go\", \"back\"), (\"really\", \"good\"), (\"deep\", \"dish\"), (\"first\", \"time\"), (\"pretty\", \"good\"), (\"food\", \"good\"), (\"next\", \"time\"), (\"great\", \"food\"), (\"come\", \"back\"), (\"food\", \"great\")]\n",
    "\n",
    "# Create binary presence features for the common n-grams\n",
    "for ngram in common_ngrams_Y:\n",
    "    df[f'has_ngram_Y_{\"_\".join(ngram)}'] = df['ngrams'].apply(lambda x: 1 if all(word in x for word in ngram) else 0)\n",
    "\n",
    "for ngram in common_ngrams_N:\n",
    "    df[f'has_ngram_N_{\"_\".join(ngram)}'] = df['ngrams'].apply(lambda x: 1 if all(word in x for word in ngram) else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewDate</th>\n",
       "      <th>reviewID</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewContent</th>\n",
       "      <th>reviewRating</th>\n",
       "      <th>reviewUsefulCount</th>\n",
       "      <th>reviewCoolCount</th>\n",
       "      <th>reviewFunnyCount</th>\n",
       "      <th>restaurantID</th>\n",
       "      <th>flagged</th>\n",
       "      <th>...</th>\n",
       "      <th>has_ngram_N_go_back</th>\n",
       "      <th>has_ngram_N_really_good</th>\n",
       "      <th>has_ngram_N_deep_dish</th>\n",
       "      <th>has_ngram_N_first_time</th>\n",
       "      <th>has_ngram_N_pretty_good</th>\n",
       "      <th>has_ngram_N_food_good</th>\n",
       "      <th>has_ngram_N_next_time</th>\n",
       "      <th>has_ngram_N_great_food</th>\n",
       "      <th>has_ngram_N_come_back</th>\n",
       "      <th>has_ngram_N_food_great</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9/22/2012</td>\n",
       "      <td>GtwU21YOQn-wf4vWRUIx6w</td>\n",
       "      <td>bNYesZ944s6IJVowOnB0iA</td>\n",
       "      <td>Unlike Next, which we'd eaten at the previous ...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pbEiXam9YJL3neCYHGwLUA</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9/22/2012</td>\n",
       "      <td>0LpVTc3</td>\n",
       "      <td>TRKxLC3y-ZvP45e5iilMtw</td>\n",
       "      <td>Probably one of the best meals I've had ever. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pbEiXam9YJL3neCYHGwLUA</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9/19/2012</td>\n",
       "      <td>tljtLzf68Fkwf</td>\n",
       "      <td>0EMm8umAqXZzyhxNpL4M9g</td>\n",
       "      <td>Service was impeccable. Experience and present...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pbEiXam9YJL3neCYHGwLUA</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9/6/2012</td>\n",
       "      <td>iSN</td>\n",
       "      <td>DlwexC7z88ymAzu45skODw</td>\n",
       "      <td>The problem with places like this, given the e...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>pbEiXam9YJL3neCYHGwLUA</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9/9/2012</td>\n",
       "      <td>Jmwrh7</td>\n",
       "      <td>kW2dk1CWihmh3g7k9N2G8A</td>\n",
       "      <td>I have no idea how to write my review - dining...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>pbEiXam9YJL3neCYHGwLUA</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  reviewDate                reviewID              reviewerID  \\\n",
       "0  9/22/2012  GtwU21YOQn-wf4vWRUIx6w  bNYesZ944s6IJVowOnB0iA   \n",
       "1  9/22/2012                 0LpVTc3  TRKxLC3y-ZvP45e5iilMtw   \n",
       "2  9/19/2012           tljtLzf68Fkwf  0EMm8umAqXZzyhxNpL4M9g   \n",
       "3   9/6/2012                     iSN  DlwexC7z88ymAzu45skODw   \n",
       "4   9/9/2012                  Jmwrh7  kW2dk1CWihmh3g7k9N2G8A   \n",
       "\n",
       "                                       reviewContent  reviewRating  \\\n",
       "0  Unlike Next, which we'd eaten at the previous ...             5   \n",
       "1  Probably one of the best meals I've had ever. ...             5   \n",
       "2  Service was impeccable. Experience and present...             3   \n",
       "3  The problem with places like this, given the e...             3   \n",
       "4  I have no idea how to write my review - dining...             5   \n",
       "\n",
       "   reviewUsefulCount  reviewCoolCount  reviewFunnyCount  \\\n",
       "0                  0                0                 0   \n",
       "1                  0                0                 0   \n",
       "2                  2                0                 0   \n",
       "3                  8                0                 3   \n",
       "4                  1                2                 0   \n",
       "\n",
       "             restaurantID  flagged  ... has_ngram_N_go_back  \\\n",
       "0  pbEiXam9YJL3neCYHGwLUA        0  ...                   0   \n",
       "1  pbEiXam9YJL3neCYHGwLUA        0  ...                   0   \n",
       "2  pbEiXam9YJL3neCYHGwLUA        0  ...                   0   \n",
       "3  pbEiXam9YJL3neCYHGwLUA        0  ...                   0   \n",
       "4  pbEiXam9YJL3neCYHGwLUA        0  ...                   0   \n",
       "\n",
       "  has_ngram_N_really_good has_ngram_N_deep_dish  has_ngram_N_first_time  \\\n",
       "0                       0                     0                       0   \n",
       "1                       0                     0                       0   \n",
       "2                       0                     0                       0   \n",
       "3                       0                     0                       0   \n",
       "4                       0                     0                       0   \n",
       "\n",
       "   has_ngram_N_pretty_good  has_ngram_N_food_good  has_ngram_N_next_time  \\\n",
       "0                        0                      0                      0   \n",
       "1                        0                      0                      0   \n",
       "2                        0                      0                      0   \n",
       "3                        0                      0                      0   \n",
       "4                        0                      0                      0   \n",
       "\n",
       "   has_ngram_N_great_food  has_ngram_N_come_back  has_ngram_N_food_great  \n",
       "0                       0                      0                       0  \n",
       "1                       0                      0                       0  \n",
       "2                       0                      0                       0  \n",
       "3                       0                      0                       0  \n",
       "4                       0                      0                       0  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.012*\"us\" + 0.011*\"food\" + 0.008*\"would\" + 0.008*\"time\" + 0.008*\"table\" + 0.007*\"one\" + 0.007*\"like\" + 0.007*\"back\" + 0.007*\"service\" + 0.006*\"place\"')\n",
      "(1, '0.025*\"food\" + 0.024*\"place\" + 0.024*\"great\" + 0.018*\"good\" + 0.012*\"service\" + 0.010*\"go\" + 0.010*\"love\" + 0.009*\"always\" + 0.008*\"get\" + 0.008*\"really\"')\n",
      "(2, '0.009*\"good\" + 0.007*\"like\" + 0.007*\"cheese\" + 0.006*\"salad\" + 0.006*\"delicious\" + 0.005*\"also\" + 0.005*\"meat\" + 0.005*\"dessert\" + 0.005*\"ordered\" + 0.005*\"sweet\"')\n",
      "(3, '0.019*\"rice\" + 0.013*\"spicy\" + 0.013*\"chicken\" + 0.013*\"good\" + 0.010*\"steak\" + 0.009*\"mexican\" + 0.009*\"chinese\" + 0.009*\"soup\" + 0.008*\"sandwich\" + 0.008*\"tacos\"')\n",
      "(4, '0.050*\"pizza\" + 0.018*\"chicago\" + 0.014*\"..\" + 0.013*\"dish\" + 0.013*\"crust\" + 0.012*\"...\" + 0.012*\"good\" + 0.012*\"best\" + 0.010*\"like\" + 0.010*\"deep\"')\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "# Create a dictionary from your tokenized text df\n",
    "dictionary = corpora.Dictionary(df['clean_tokens'])\n",
    "\n",
    "# Create a bag-of-words (BoW) corpus\n",
    "corpus = [dictionary.doc2bow(text) for text in df['clean_tokens']]\n",
    "\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Train an LDA model\n",
    "lda_model = LdaModel(corpus, num_topics=5, id2word=dictionary, passes=15)\n",
    "\n",
    "# Print the topics and their top keywords\n",
    "topics = lda_model.print_topics(num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "\n",
    "# Assign topics to documents\n",
    "topics_in_documents = [lda_model[doc] for doc in corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split topics into fake vs real reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common Topics for flagged 'Y' reviews:\n",
      "(0, '0.033*\"pizza\" + 0.012*\"good\" + 0.012*\"best\" + 0.010*\"chicago\" + 0.010*\"like\" + 0.009*\"tacos\" + 0.009*\"food\" + 0.009*\"mexican\" + 0.009*\"place\" + 0.008*\"steak\"')\n",
      "(1, '0.016*\"us\" + 0.010*\"food\" + 0.010*\"table\" + 0.009*\"would\" + 0.008*\"time\" + 0.008*\"restaurant\" + 0.007*\"back\" + 0.007*\"service\" + 0.007*\"minutes\" + 0.007*\"one\"')\n",
      "(2, '0.017*\"food\" + 0.015*\"good\" + 0.015*\"place\" + 0.012*\"...\" + 0.010*\"like\" + 0.008*\"great\" + 0.007*\"go\" + 0.007*\"really\" + 0.007*\"service\" + 0.006*\"get\"')\n",
      "(3, '0.032*\"great\" + 0.025*\"food\" + 0.018*\"place\" + 0.015*\"love\" + 0.013*\"service\" + 0.011*\"good\" + 0.010*\"always\" + 0.008*\"restaurant\" + 0.008*\"go\" + 0.008*\"delicious\"')\n",
      "(4, '0.008*\"crab\" + 0.008*\"cake\" + 0.008*\"fogo\" + 0.005*\"brazilian\" + 0.005*\"de\" + 0.005*\"best\" + 0.005*\"one\" + 0.005*\"..\" + 0.004*\"top\" + 0.004*\"great\"')\n",
      "Common Topics for flagged 'N' reviews:\n",
      "(0, '0.012*\"us\" + 0.012*\"food\" + 0.009*\"table\" + 0.009*\"would\" + 0.009*\"time\" + 0.008*\"place\" + 0.008*\"back\" + 0.008*\"good\" + 0.008*\"service\" + 0.007*\"...\"')\n",
      "(1, '0.011*\"good\" + 0.007*\"delicious\" + 0.007*\"pork\" + 0.006*\"sauce\" + 0.006*\"chicken\" + 0.006*\"salad\" + 0.006*\"also\" + 0.006*\"cheese\" + 0.006*\"like\" + 0.006*\"sweet\"')\n",
      "(2, '0.009*\"like\" + 0.008*\"one\" + 0.007*\"bar\" + 0.007*\"wine\" + 0.006*\"experience\" + 0.006*\"food\" + 0.005*\"dining\" + 0.005*\"menu\" + 0.005*\"restaurant\" + 0.005*\"course\"')\n",
      "(3, '0.024*\"food\" + 0.024*\"place\" + 0.021*\"great\" + 0.018*\"good\" + 0.010*\"go\" + 0.010*\"service\" + 0.010*\"love\" + 0.010*\"always\" + 0.009*\"get\" + 0.008*\"really\"')\n",
      "(4, '0.037*\"pizza\" + 0.019*\"beer\" + 0.014*\"good\" + 0.014*\"cheese\" + 0.012*\"chicago\" + 0.012*\"burger\" + 0.010*\"crust\" + 0.010*\"like\" + 0.010*\"dish\" + 0.009*\"fries\"')\n"
     ]
    }
   ],
   "source": [
    "def find_common_topics(data_subset, num_topics):\n",
    "    # Create a dictionary from tokenized text data\n",
    "    dictionary = corpora.Dictionary(data_subset['clean_tokens'])\n",
    "\n",
    "    # Create a bag-of-words (BoW) corpus\n",
    "    corpus = [dictionary.doc2bow(text) for text in data_subset['clean_tokens']]\n",
    "\n",
    "    # Train an LDA model\n",
    "    lda_model = LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=15)\n",
    "\n",
    "    # Print the topics and their top keywords\n",
    "    topics = lda_model.print_topics(num_words=10)\n",
    "    for topic in topics:\n",
    "        print(topic)\n",
    "\n",
    "    # Assign topics to documents\n",
    "    topics_in_documents = [lda_model[doc] for doc in corpus]\n",
    "\n",
    "# Separate the data into two subsets based on the \"flagged\" category\n",
    "flagged_Y_data = df[df['flagged'] == 1]\n",
    "flagged_N_data = df[df['flagged'] == 0]\n",
    "\n",
    "# Find common topics for flagged 'Y' reviews\n",
    "print(\"Common Topics for flagged 'Y' reviews:\")\n",
    "find_common_topics(flagged_Y_data, num_topics=5)\n",
    "\n",
    "# Find common topics for flagged 'N' reviews\n",
    "print(\"Common Topics for flagged 'N' reviews:\")\n",
    "find_common_topics(flagged_N_data, num_topics=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
